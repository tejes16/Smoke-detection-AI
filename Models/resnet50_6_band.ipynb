# -*- coding: utf-8 -*-
"""resnet50_6_band.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OKdE759uG83_eNjLSsFQj4Fw6QKwZCT3
"""

!pip install rasterio
!pip install Pillow
!pip install -U tensorflow
!pip install -U keras
!pip install git+https://github.com/qubvel/segmentation_models

!pip install tensorflow==2.12.0

!pip install -U -q segmentation-models
!pip install -q tensorflow==2.2.1
!pip install -q keras==2.5
import os
os.environ["SM_FRAMEWORK"] = "tf.keras"

from tensorflow import keras
import segmentation_models as sm

import tensorflow as tf
import cv2
import matplotlib
import os,re
import rasterio
from random import randint
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from rasterio.plot import show, show_hist
from sklearn.model_selection import train_test_split
import sys,traceback,signal
import keras
import segmentation_models as sm

import cv2
import os
import rasterio
import numpy as np
from sklearn.model_selection import train_test_split
import segmentation_models as sm

dataset_path = "/content/drive/MyDrive/Tiles"
image_folder = os.path.join(dataset_path, "Rasters")
mask_folder = os.path.join(dataset_path, "Masks")

image_files = sorted(os.listdir(image_folder))
mask_files = sorted(os.listdir(mask_folder))

# Check if the number of images and masks match
if len(image_files) != len(mask_files):
    raise ValueError("Number of images and masks don't match")

num_images = len(image_files)

# Lists to store the loaded images and masks
images = []
masks = []

for i in range(num_images):
    image_path = os.path.join(image_folder, image_files[i])
    mask_path = os.path.join(mask_folder, mask_files[i])

    # Open the image and mask using rasterio
    with rasterio.open(image_path) as src:
        image = src.read()  # Read all the channels

    with rasterio.open(mask_path) as src:
        mask = src.read(1)  # Read only the first channel (assuming the mask is single-channel)

    # Append the image and mask to the respective lists
    images.append(image)
    masks.append(mask)

# Convert the lists to numpy arrays
images = np.array(images)
masks = np.array(masks)

# Print the shape of the loaded dataset
print("Images shape:", images.shape)
print("Masks shape:", masks.shape)

##########################################################

intxtrain, intxtest, intytrain, intytest = train_test_split(images, masks, test_size=0.2, random_state=5)

##########################################################

BACKBONE = "resnet50"
preprocess = sm.get_preprocessing(BACKBONE)

############################################################

model = sm.Unet(backbone_name=BACKBONE, encoder_weights=None, input_shape=(256, 256, 6))
model.compile('Adam', loss=sm.losses.bce_jaccard_loss, metrics=[sm.metrics.iou_score])
model.summary()

############################################################

intxtrain = np.transpose(intxtrain, (0, 2, 3, 1))
intxtest = np.transpose(intxtest, (0, 2, 3, 1))
intytrain = (intytrain / 255).astype(np.float32)
intytest = (intytest / 255).astype(np.float32)

intxval = intxtest[:(len(intxtest) // 2)]
intxtest = intxtest[(len(intxtest) // 2):len(intxtest)]
intyval = intytest[:(len(intytest) // 2)]
intytest = intytest[(len(intytest) // 2):len(intytest)]

#############################################################

history = model.fit(x=intxtrain, y=intytrain, batch_size=64, verbose=1, epochs=20, validation_data=(intxval, intyval))

# Evaluate the model on the test set
score = model.evaluate(intxtest, intytest, verbose=0)
print("Test IoU Score:", score[1])

# Get the training history
train_loss = history.history['loss']
val_loss = history.history['val_loss']
train_iou = history.history['iou_score']
val_iou = history.history['val_iou_score']
epochs = range(1, len(train_loss) + 1)

# Plot the training and validation loss
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs, train_loss, 'b-', label='Training Loss')
plt.plot(epochs, val_loss, 'r-', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Plot the training and validation IoU
plt.subplot(1, 2, 2)
plt.plot(epochs, train_iou, 'b-', label='Training IoU')
plt.plot(epochs, val_iou, 'r-', label='Validation IoU')
plt.title('Training and Validation IoU')
plt.xlabel('Epochs')
plt.ylabel('IoU Score')
plt.legend()

# Show the plots
plt.tight_layout()
plt.show()

model.save("smoke_resent50_20epochs.h5")

from keras.models import load_model
import tensorflow.keras.backend as K
from tensorflow.keras.utils import CustomObjectScope
import segmentation_models as sm

# Define the custom loss function
def binary_crossentropy_plus_jaccard_loss(y_true, y_pred):
    bce_loss = K.binary_crossentropy(y_true, y_pred)
    jaccard_loss = sm.losses.jaccard_loss(y_true, y_pred)
    return bce_loss + jaccard_loss

# Define the custom metric function
def iou_score(y_true, y_pred):
    iou = sm.metrics.iou_score(y_true, y_pred)
    return iou

# Register the custom loss and metric functions
with CustomObjectScope({'binary_crossentropy_plus_jaccard_loss': binary_crossentropy_plus_jaccard_loss,
                        'iou_score': iou_score}):
    model = load_model('/content/sample_data/smoke_resent50_20epochs.h5')

# Compile the model with the desired optimizer, loss function, and metrics
model.compile(optimizer='adam',
              loss=binary_crossentropy_plus_jaccard_loss,
              metrics=[iou_score])


# Train the model for additional epochs
history = model.fit(x=intxtrain, y=intytrain, batch_size=32, verbose=1, epochs=20, validation_data=(intxval, intyval))

# Save the updated model
model.save('smoke_resnet50_40epoch.h5')

# Evaluate the model on the test set
score = model.evaluate(intxtest, intytest, verbose=0)
print("Test IoU Score:", score[1])

# Get the training history
train_loss = history.history['loss']
val_loss = history.history['val_loss']
train_iou = history.history['iou_score']
val_iou = history.history['val_iou_score']
epochs = range(1, len(train_loss) + 1)

# Plot the training and validation loss
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs, train_loss, 'b-', label='Training Loss')
plt.plot(epochs, val_loss, 'r-', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Plot the training and validation IoU
plt.subplot(1, 2, 2)
plt.plot(epochs, train_iou, 'b-', label='Training IoU')
plt.plot(epochs, val_iou, 'r-', label='Validation IoU')
plt.title('Training and Validation IoU')
plt.xlabel('Epochs')
plt.ylabel('IoU Score')
plt.legend()

# Show the plots
plt.tight_layout()
plt.show()

from google.colab import files

# Specify the path of the file you want to download
file_path = "/content/smoke_resnet50_40epoch"

# Download the file
files.download(file_path)

from keras.models import load_model
import tensorflow.keras.backend as K
from tensorflow.keras.utils import CustomObjectScope
import segmentation_models as sm

# Define the custom loss function
def binary_crossentropy_plus_jaccard_loss(y_true, y_pred):
    bce_loss = K.binary_crossentropy(y_true, y_pred)
    jaccard_loss = sm.losses.jaccard_loss(y_true, y_pred)
    return bce_loss + jaccard_loss

# Define the custom metric function
def iou_score(y_true, y_pred):
    iou = sm.metrics.iou_score(y_true, y_pred)
    return iou

# Register the custom loss and metric functions
with CustomObjectScope({'binary_crossentropy_plus_jaccard_loss': binary_crossentropy_plus_jaccard_loss,
                        'iou_score': iou_score}):
    model = load_model('/content/smoke_resnet50_40epoch.h5')

# Compile the model with the desired optimizer, loss function, and metrics
model.compile(optimizer='adam',
              loss=binary_crossentropy_plus_jaccard_loss,
              metrics=[iou_score])


# Train the model for additional epochs
history = model.fit(x=intxtrain, y=intytrain, batch_size=32, verbose=1, epochs=60, validation_data=(intxval, intyval))

# Save the updated model
model.save('smoke_resnet50_100epoch.h5')

# Evaluate the model on the test set
score = model.evaluate(intxtest, intytest, verbose=0)
print("Test IoU Score:", score[1])

# Get the training history
train_loss = history.history['loss']
val_loss = history.history['val_loss']
train_iou = history.history['iou_score']
val_iou = history.history['val_iou_score']
epochs = range(1, len(train_loss) + 1)

# Plot the training and validation loss
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs, train_loss, 'b-', label='Training Loss')
plt.plot(epochs, val_loss, 'r-', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Plot the training and validation IoU
plt.subplot(1, 2, 2)
plt.plot(epochs, train_iou, 'b-', label='Training IoU')
plt.plot(epochs, val_iou, 'r-', label='Validation IoU')
plt.title('Training and Validation IoU')
plt.xlabel('Epochs')
plt.ylabel('IoU Score')
plt.legend()

# Show the plots
plt.tight_layout()
plt.show()

from keras.models import load_model
import tensorflow.keras.backend as K
from tensorflow.keras.utils import CustomObjectScope
import segmentation_models as sm

# Define the custom loss function
def binary_crossentropy_plus_jaccard_loss(y_true, y_pred):
    bce_loss = K.binary_crossentropy(y_true, y_pred)
    jaccard_loss = sm.losses.jaccard_loss(y_true, y_pred)
    return bce_loss + jaccard_loss

# Define the custom metric function
def iou_score(y_true, y_pred):
    iou = sm.metrics.iou_score(y_true, y_pred)
    return iou

# Register the custom loss and metric functions
with CustomObjectScope({'binary_crossentropy_plus_jaccard_loss': binary_crossentropy_plus_jaccard_loss,
                        'iou_score': iou_score}):
    model = load_model('/content/sample_data/smoke_resent50_20epochs.h5')

# Compile the model with the desired optimizer, loss function, and metrics
model.compile(optimizer='adam',
              loss=binary_crossentropy_plus_jaccard_loss,
              metrics=[iou_score])


# Train the model for additional epochs
history = model.fit(x=intxtrain, y=intytrain, batch_size=32, verbose=1, epochs=60, validation_data=(intxval, intyval))

# Save the updated model
model.save('smoke_resnet50_100epoch.h5')
